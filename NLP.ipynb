{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "406f478e-0174-4d00-ba66-6777522d9f3a",
   "metadata": {},
   "source": [
    "# Natural Language Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb367be-598f-404c-ad13-8ae260a1d6aa",
   "metadata": {},
   "source": [
    "- Ability to understand and interpret Language\n",
    "\n",
    "- Types of text data:\n",
    "    - Messages\n",
    "    - Email\n",
    "    - Any article on the internet\n",
    "\n",
    "- Applications:\n",
    "    - Chatbots - (FAQ based, conversation)\n",
    "    - Identify sentiment of the language ( Review on the internet for some product or some movie )\n",
    "    - Topic Modelling (what are the trending topics Quora?)\n",
    "    - Machine Translation\n",
    "    - Text Completion\n",
    "    - Home assistants\n",
    "    -etc etc\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60de8820-5bbb-422c-a08c-3ace0a9a70c6",
   "metadata": {},
   "source": [
    "- Topics :\n",
    "    - Regular Expression\n",
    "    - Reading text data ( using context manager)\n",
    "    - Text Processing\n",
    "        - Tokenisation\n",
    "        - Stemming & Lemmatisation\n",
    "        - StopWords\n",
    "        - Converting text data to vectors:\n",
    "            - One Hot Encoding\n",
    "            - Bag of Words\n",
    "            - TF- IDF\n",
    "            - Count Vectorisor\n",
    "            - NLTK and Spacy\n",
    "                - POS \n",
    "                - NER\n",
    "                - Training models on text data\n",
    "        - Projects:\n",
    "            - Email Classification (Spam / Ham classification)\n",
    "            - Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de41b60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2759577a-df42-46cd-8732-9f4f78d650c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c7c9e8-806b-48da-a6e7-31f121537b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m spacy download en_core_web_sm     #----> install english core library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b457d727-92db-4ff7-8ff4-97edf73631b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: nltk in c:\\programdata\\anaconda3\\lib\\site-packages (3.7)\n",
      "Requirement already satisfied: joblib in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (4.64.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (2022.7.9)\n",
      "Requirement already satisfied: click in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "e16011c6-f218-4837-8d52-ec9e802af267",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "901670da-36a2-4993-b1cc-284ed5346198",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f9a1365-50ce-41e0-ac7c-6387f5c52422",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb68114-f5bc-4c49-98d0-720bc2fea79e",
   "metadata": {},
   "source": [
    "- Terminologies\n",
    "    - Corpus ---> Entire Dataset\n",
    "    - Document\n",
    "    - Token ---> one word or one sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0f81714-4804-4f11-ac55-cff9726f6f9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I like this book',\n",
       " 'I dont like football',\n",
       " 'I like reading stories',\n",
       " 'I am a football fan']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_data = [\"I like this book\", \"I dont like football\", \"I like reading stories\", \"I am a football fan\"]\n",
    "text_data   #----->corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e1a72881-42ed-44f4-a9a8-d7c9eb5db49e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          I like this book\n",
       "1      I dont like football\n",
       "2    I like reading stories\n",
       "3       I am a football fan\n",
       "dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_series = pd.Series(text_data)\n",
    "text_series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262da94a-f6ef-46ba-b07a-8f9bfeb657ff",
   "metadata": {},
   "source": [
    "    \"I like this book\",  #--->Document\n",
    "    \"I dont like football\",  # ----> Document\n",
    "    \"I like reading stories\", # -----> Document\n",
    "    \"I am a football fan\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0304ab-1561-464b-8c00-ec96341c3504",
   "metadata": {},
   "source": [
    "    Tokenisation\n",
    "        - Splitting the data into words or sentences ( word tokenisation & Sentence tokenisation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "523a19ba-5d2d-44f9-9e04-260a15a2bd7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I like this book',\n",
       " 'I dont like football',\n",
       " 'I like reading stories',\n",
       " 'I am a football fan']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37037e6-f4fe-44f8-b638-2feb045baed7",
   "metadata": {},
   "source": [
    "    Document --> 'I like this book very much'\n",
    "\n",
    "    Tokens :    \n",
    "            I, like, this , book , very , much   ( Unigram)\n",
    "            I like, like this, this book, book very,  very much  ( bi-gram)\n",
    "            I like this, like this book, this book very, book very much  ( 3- gram)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "b15fc9f6-a132-4582-8ac0-50fbab239b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e272d3-72f1-4c3e-a2a4-e6a704481a7c",
   "metadata": {},
   "source": [
    "# Tokenisation\n",
    "    - Word Tokenisation\n",
    "    - Sentence Tokenisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "c0d7ae07-ee2e-4706-8379-e854061232c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9fd33370-dd6a-4e2c-83b5-42d766d27dbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I like this book',\n",
       " 'I dont like football',\n",
       " 'I like reading stories',\n",
       " 'I am a football fan']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9f83b11e-fffe-465a-a8a1-45eb0f444cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_text = \"I am liking football very much. I watch football every day\"  # Document which has 2 sentences\n",
    "\n",
    "doc = nlp(single_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f5cd3e0c-7b09-4e97-800b-231118d284df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.doc.Doc"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "342e2215-b15e-4170-801e-886df68d3915",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(single_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fa62d856-96c2-46c5-ae41-e2c081fcff48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[I am liking football very much., I watch football every day]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Tokennize the sentences\n",
    "list(doc.sents)\n",
    "tokenized_sentences = [sentence for sentence in doc.sents]\n",
    "tokenized_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "86061926-a91c-41cf-8f9f-007c2f3b89b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I\n",
      "am\n",
      "liking\n",
      "football\n",
      "very\n",
      "much\n",
      ".\n",
      "I\n",
      "watch\n",
      "football\n",
      "every\n",
      "day\n"
     ]
    }
   ],
   "source": [
    "# Word tokenisation\n",
    "for sentence in doc.sents:\n",
    "    for word in sentence:\n",
    "        print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c743484e-9d9e-44c8-819b-f4a59a08103f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[I, am, liking, football, very, much, ., I, watch, football, every, day]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(doc)  # ---> word tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1d8593c3-034b-4844-8c38-02e3c8d55e6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[I am liking football very much., I watch football every day]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(doc.sents)  # ----> sentence tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e4e22fb3-05a0-4f35-bc05-dd07a094b565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I\n",
      "am\n",
      "liking\n",
      "football\n",
      "very\n",
      "much\n",
      ".\n",
      "I\n",
      "watch\n",
      "football\n",
      "every\n",
      "day\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2a944baf-6c6c-4826-b9ee-081f0fbfc79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Try this in NLTK\n",
    "\n",
    "# from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "# sent_tokenize(single_text)\n",
    "# word_tokenize(single_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2cb62269-d5b2-43b6-909b-93774f312517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['_', '__bytes__', '__class__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__len__', '__lt__', '__ne__', '__new__', '__pyx_vtable__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__unicode__', 'ancestors', 'check_flag', 'children', 'cluster', 'conjuncts', 'dep', 'dep_', 'doc', 'ent_id', 'ent_id_', 'ent_iob', 'ent_iob_', 'ent_kb_id', 'ent_kb_id_', 'ent_type', 'ent_type_', 'get_extension', 'has_dep', 'has_extension', 'has_head', 'has_morph', 'has_vector', 'head', 'i', 'idx', 'iob_strings', 'is_alpha', 'is_ancestor', 'is_ascii', 'is_bracket', 'is_currency', 'is_digit', 'is_left_punct', 'is_lower', 'is_oov', 'is_punct', 'is_quote', 'is_right_punct', 'is_sent_end', 'is_sent_start', 'is_space', 'is_stop', 'is_title', 'is_upper', 'lang', 'lang_', 'left_edge', 'lefts', 'lemma', 'lemma_', 'lex', 'lex_id', 'like_email', 'like_num', 'like_url', 'lower', 'lower_', 'morph', 'n_lefts', 'n_rights', 'nbor', 'norm', 'norm_', 'orth', 'orth_', 'pos', 'pos_', 'prefix', 'prefix_', 'prob', 'rank', 'remove_extension', 'right_edge', 'rights', 'sent', 'sent_start', 'sentiment', 'set_extension', 'set_morph', 'shape', 'shape_', 'similarity', 'subtree', 'suffix', 'suffix_', 'tag', 'tag_', 'tensor', 'text', 'text_with_ws', 'vector', 'vector_norm', 'vocab', 'whitespace_']\n"
     ]
    }
   ],
   "source": [
    "print(dir(doc[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "34680099-b092-4271-b3f4-5d733bea9d4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "liking"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "41571f6e-67c4-47ea-bfc7-c3e7e04f2373",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[2].is_currency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0b69d26e-8364-4516-bf4e-c5c203fd4fb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[2].is_lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e7e308c9-815e-4502-885a-3dd8740ab778",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[2].is_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1ba478-cf04-46bb-8068-4b16fbb5679d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "194b5f9f-0a42-4722-8aa1-fe687cc43baf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(liking, 'like')"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[2] , doc[2].lemma_   # ----> Lemmatisation of the token ---> converts the token to root form"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49f3f85-aa66-4129-8ef8-ef2b03d44697",
   "metadata": {},
   "source": [
    "- Lemmatisation\n",
    "\n",
    "        good   ----> good\n",
    "        better ----> good\n",
    "        best   ---> good\n",
    "\n",
    "\n",
    "        go     ---> go\n",
    "        going  ---> go\n",
    "        gone   ---> go\n",
    "        went   ---> go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7b3d8329-8b9e-4f2a-94ae-da6ac640c2c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(I, True)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[0] ,doc[0].is_alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17baeaf-ac80-42d5-b453-3c6db1d964da",
   "metadata": {},
   "source": [
    "# Part of Speech (POS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "8da9cd21-00ed-478f-b849-3dd8f77d4924",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>lemma</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I</td>\n",
       "      <td>I</td>\n",
       "      <td>PRON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>am</td>\n",
       "      <td>be</td>\n",
       "      <td>AUX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>liking</td>\n",
       "      <td>like</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>football</td>\n",
       "      <td>football</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>very</td>\n",
       "      <td>very</td>\n",
       "      <td>ADV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>much</td>\n",
       "      <td>much</td>\n",
       "      <td>ADV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>I</td>\n",
       "      <td>I</td>\n",
       "      <td>PRON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>watched</td>\n",
       "      <td>watch</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>football</td>\n",
       "      <td>football</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>every</td>\n",
       "      <td>every</td>\n",
       "      <td>DET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>day</td>\n",
       "      <td>day</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       token     lemma    pos\n",
       "0          I         I   PRON\n",
       "1         am        be    AUX\n",
       "2     liking      like   VERB\n",
       "3   football  football   NOUN\n",
       "4       very      very    ADV\n",
       "5       much      much    ADV\n",
       "6          .         .  PUNCT\n",
       "7          I         I   PRON\n",
       "8    watched     watch   VERB\n",
       "9   football  football   NOUN\n",
       "10     every     every    DET\n",
       "11       day       day   NOUN"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_text = 'I am liking football very much. I watched football every day'\n",
    "\n",
    "token_list = []\n",
    "lemma_list = []\n",
    "pos_list   = []\n",
    "\n",
    "for token in nlp(single_text):\n",
    "    token_list.append(token)\n",
    "    lemma_list.append(token.lemma_)\n",
    "    pos_list.append(token.pos_)\n",
    "    # print(f\"{token},\\t  { token.lemma_}\")\n",
    "    \n",
    "df = pd.DataFrame({\"token\":token_list,\n",
    "                  \"lemma\":lemma_list,\n",
    "                  \"pos\":pos_list})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885d21db-6c0f-4dc0-96f5-8ae2df06683c",
   "metadata": {},
   "source": [
    "# Named Entity Recognition (NER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "de146e01-52a1-420b-95b0-0cf3eb6b4a52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Facebook Inc---> ORG---> Companies, agencies, institutions, etc.\n",
      "US---> GPE---> Countries, cities, states\n",
      "Google---> ORG---> Companies, agencies, institutions, etc.\n",
      "$200 Billion---> MONEY---> Monetary values, including unit\n",
      "France---> GPE---> Countries, cities, states\n"
     ]
    }
   ],
   "source": [
    "single_text = 'I am working at Facebook Inc in US. Facebook and Google are big companies with $200 Billion worth. Tesla is also big company in France. '\n",
    "\n",
    "for entity in nlp(single_text).ents:\n",
    "    print(f\"{entity}---> {entity.label_}---> {spacy.explain(entity.label_)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c95f41-b510-4648-8579-c8fddb38f5e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "8d36c555-4da8-4dd0-97d8-7ecb6c4e45d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "a3c19407-9962-403d-bd74-6386277520e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">I am working at \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Facebook Inc\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " in \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    US\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ". Facebook and \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Google\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " are big companies with \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    $200 Billion\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\n",
       "</mark>\n",
       " worth. Tesla is also big company in \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    France\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ". </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(nlp(single_text), style = \"ent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417d66a2-1aa8-4f28-81a4-fcf7e6cd80e4",
   "metadata": {},
   "source": [
    "## Stemming and Lemmatisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b2f7ad-cebd-4f38-86ae-47d14d67ab10",
   "metadata": {},
   "source": [
    "- Stemming ( converts to the root word ---> rule based ( eg. it removed 'y' from the end or 'er' from the end) )\n",
    "\n",
    "        happy    --> happi   ---> ( may not give meaningful words)\n",
    "        happier  --> happi\n",
    "        happiest --> happi\n",
    "\n",
    "        ability ---> abiliti\n",
    "\n",
    "        going   --> go\n",
    "        seeing  --> see\n",
    "        caring  --> car  ( it should be care)  --> meaningless\n",
    "\n",
    "\n",
    "\n",
    "- Lemmatisation (gives meaningful words, takes into account the grammar and english vocabulary)\n",
    "\n",
    "        good   ----> good\n",
    "        better ----> good\n",
    "        best   ---> good\n",
    "\n",
    "\n",
    "        go     ---> go\n",
    "        going  ---> go\n",
    "        gone   ---> go\n",
    "        went   ---> go"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98686d67-b580-4b56-b3a3-1b39b4f318e3",
   "metadata": {},
   "source": [
    "# Filtering  the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "b2c39229-cb78-4a7c-8b81-e0ddaab004cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "earnings_text= \"\"\"Microsoft Corp. today announced the following results for the quarter ended December 31, 2021, as compared to the corresponding period of last fiscal year:\n",
    "\n",
    "·         Revenue was $51.7 billion and increased 20%\n",
    "·         Operating income was $22.2 billion and increased 24%\n",
    "·         Net income was $18.8 billion and increased 21%\n",
    "·         Diluted earnings per share was $2.48 and increased 22%\n",
    "“Digital technology is the most malleable resource at the world’s disposal to overcome constraints and reimagine everyday work and life,” said Satya Nadella, chairman and chief executive officer of Microsoft. “As tech as a percentage of global GDP continues to increase, we are innovating and investing across diverse and growing markets, with a common underlying technology stack and an operating model that reinforces a common strategy, culture, and sense of purpose.”\n",
    "“Solid commercial execution, represented by strong bookings growth driven by long-term Azure commitments, increased Microsoft Cloud revenue to $22.1 billion, up 32% year over year” said Amy Hood, executive vice president and chief financial officer of Microsoft.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "014749da-7b14-4c87-b6df-e94e0f1e23a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Microsoft Corp. today announced the following results for the quarter ended December 31, 2021, as compared to the corresponding period of last fiscal year:\\n\\n·         Revenue was $51.7 billion and increased 20%\\n·         Operating income was $22.2 billion and increased 24%\\n·         Net income was $18.8 billion and increased 21%\\n·         Diluted earnings per share was $2.48 and increased 22%\\n“Digital technology is the most malleable resource at the world’s disposal to overcome constraints and reimagine everyday work and life,” said Satya Nadella, chairman and chief executive officer of Microsoft. “As tech as a percentage of global GDP continues to increase, we are innovating and investing across diverse and growing markets, with a common underlying technology stack and an operating model that reinforces a common strategy, culture, and sense of purpose.”\\n“Solid commercial execution, represented by strong bookings growth driven by long-term Azure commitments, increased Microsoft Cloud revenue to $22.1 billion, up 32% year over year” said Amy Hood, executive vice president and chief financial officer of Microsoft.'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "earnings_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "bad31c4d-0650-444b-8041-b7f6b069d4f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Microsoft,\n",
       " Corp.,\n",
       " today,\n",
       " announced,\n",
       " the,\n",
       " following,\n",
       " results,\n",
       " for,\n",
       " the,\n",
       " quarter,\n",
       " ended,\n",
       " December,\n",
       " 31,\n",
       " 2021,\n",
       " as]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(earnings_text)\n",
    "filtered_tokens = []\n",
    "\n",
    "for token in doc:\n",
    "    if token.pos_ not in [\"SPACE\",\"PUNCT\",\"X\"]:\n",
    "        filtered_tokens.append(token)\n",
    "filtered_tokens[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e97a7e-2aff-4aae-b2cb-e362e681640b",
   "metadata": {},
   "source": [
    "## StopWords\n",
    "\n",
    "    - Commomly used words like I, me, they, them , there, this, that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "2366baea-995e-4078-aecc-043af3cd1a10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eat good food sleep read'"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"I will eat good food then go to sleep and then i will go and read something\"\n",
    "\n",
    "doc = nlp(text)\n",
    "\n",
    "filtered_text = []\n",
    "for token in doc:\n",
    "    if not token.is_stop:\n",
    "        filtered_text.append(token.text)\n",
    "        \n",
    "(filtered_text)\n",
    "text_without_stop  = \" \".join(filtered_text)\n",
    "text_without_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3cc638-fa4c-4d79-a555-79cd20f05797",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac54c49-3019-4ec1-9689-14fdf2362df8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "00e68441-2cca-4e8e-89ca-dd22f11890a0",
   "metadata": {},
   "source": [
    "# Vectorisation of the data\n",
    "    - Convert the text document into numerical format\n",
    "    \n",
    "    - Bag of Words ( BOW) \n",
    "        - Count Vectorisation\n",
    "        - TF-IDF ( Term Frequency & Inverse Document Frequency)\n",
    "    - Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "00c67e8d-adbf-4525-b3a2-094f83bcbae5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I am working at Facebook Inc in US. Facebook and Google are big companies with $200 Billion worth. Tesla is also big company in France. '"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bcb28fa-a44e-4e89-99e9-b91671f7f92a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f67acc-55d3-46f6-ba6e-bb8489b4131a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "de27a2c7-2413-4f06-9f3c-b25ba4c733e6",
   "metadata": {},
   "source": [
    "### Converting a simple text  corpus to numerical matrix using CountVectorisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "e3a1f465-901a-4cb9-8eda-d1960f3aa3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data = [\"I like this book\", \n",
    "             \"I dont like football\", \n",
    "             \"I am reading this book\", \n",
    "             \"I am a football fan\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "a7282dc4-09d8-48dc-b139-7994066e201b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I like this book</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I dont like football</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I am reading this book</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I am a football fan</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 features  label\n",
       "0        I like this book      1\n",
       "1    I dont like football      0\n",
       "2  I am reading this book      1\n",
       "3     I am a football fan      0"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_df = pd.DataFrame({\"features\":text_data, \"label\":[1,0,1,0]})\n",
    "text_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "319bb471-a316-43a7-a9ee-2fc8470dae20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "eb2c6ceb-7874-40df-9b3a-74cfe3cfafc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "'''Count Vectorizer\n",
    "\n",
    "        i   like   this   book   dont   football    am   reading   a   fan\n",
    "Row1    1     1     1        1      0        0       0     0       0    0\n",
    "Row2    1     1     0        0      1        1       0     0       0    0\n",
    "Row3\n",
    "Row3\n",
    "\n",
    "'''\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "ae923070-678e-412a-bdb8-60873c032fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "vectors = vectorizer.fit_transform(text_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ac99ca-2c0b-40c3-8f35-536b35d6bf65",
   "metadata": {},
   "source": [
    "    - Sparse Matrix ---> Has lot of zeros and very less values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "60ef0262-12d1-463e-bbf2-e608c5157296",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I like this book',\n",
       " 'I dont like football',\n",
       " 'I am reading this book',\n",
       " 'I am a football fan']"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "25f194cb-4e6b-43dc-a515-77fb0b5d6e5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 0, 0, 1, 0, 1],\n",
       "       [0, 0, 1, 0, 1, 1, 0, 0],\n",
       "       [1, 1, 0, 0, 0, 0, 1, 1],\n",
       "       [1, 0, 0, 1, 1, 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors.toarray()  # ----> Text data in vectorized format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "4c6f58a2-cc68-440b-9c3f-e7db5fc9f522",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['am', 'book', 'dont', 'fan', 'football', 'like', 'reading', 'this'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names_out()  # -----> doesnt consider i and a  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "bef55375-cac4-42aa-b48b-5ebb1d822a33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>am</th>\n",
       "      <th>book</th>\n",
       "      <th>dont</th>\n",
       "      <th>fan</th>\n",
       "      <th>football</th>\n",
       "      <th>like</th>\n",
       "      <th>reading</th>\n",
       "      <th>this</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   am  book  dont  fan  football  like  reading  this  label\n",
       "0   0     1     0    0         0     1        0     1      1\n",
       "1   0     0     1    0         1     1        0     0      0\n",
       "2   1     1     0    0         0     0        1     1      1\n",
       "3   1     0     0    1         1     0        0     0      0"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_set = pd.DataFrame(data = vectors.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "feature_set[\"label\"] = text_df[\"label\"]\n",
    "feature_set   #---> data prepared for machine learning model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "4f43340e-f6f2-4522-a684-0d8d663d5991",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "clf_svm = svm.SVC(kernel = \"linear\")\n",
    "\n",
    "X_train =  vectors.toarray()\n",
    "y_train = text_df[\"label\"]\n",
    "\n",
    "clf_svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b6646b-77ea-4e3a-bd52-c300d730c42f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "1b9fc26a-cd35-48b5-90fa-8301d03c75a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    0\n",
       "2    1\n",
       "3    0\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "e0107cf1-adca-4804-bb73-544e231126d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I like this book',\n",
       " 'I dont like football',\n",
       " 'I am reading this book',\n",
       " 'I am a football fan']"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "3242c78c-a76a-4b99-b19f-dba2aa4de516",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_text = [\"I like this book\",\"People watch football\", \"i  read books\",\"football is good\",\"books\"]\n",
    "pred_vector = (vectorizer.transform(pred_text)).toarray()\n",
    "\n",
    "\n",
    "# print(pred_vector)\n",
    "\n",
    "clf_svm.predict(pred_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "2e6d0ee8-7959-4950-9b08-f03aec5434f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3x8 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 2 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c1bf04-59a7-4e5a-821f-9a9303565529",
   "metadata": {},
   "source": [
    "#### Another Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "60b26d1a-4127-4cc7-9a84-9bbf9dc864a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train_x = [\"i love the book\", \"this is a great book\", \"the fit is great\", \"i love the shoes\" ]\n",
    "train_y = [\"BOOKS\", \"BOOKS\", \"CLOTHING\", \"CLOTHING\"]\n",
    "\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "train_x_vectors = vectorizer.fit_transform(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "9590d2b6-7069-428a-9029-21fce8398105",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "clf_svm = svm.SVC(kernel = \"linear\")\n",
    "clf_svm.fit(train_x_vectors, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "bae43625-6a30-434b-ac7c-cd736f19986b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CLOTHING', 'BOOKS', 'BOOKS', 'CLOTHING'], dtype='<U8')"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x = [\"shoes fit well\", \"i love to read this\",\"interesting book to read\", \"i like the story\"]\n",
    "test_x_vectors = vectorizer.transform(test_x)\n",
    "clf_svm.predict(test_x_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0433282f-64b4-4bb0-8c31-5ea91196b2ff",
   "metadata": {},
   "source": [
    "    - Disadvantages of Count Vectorisation:\n",
    "            - It only considers those words which are present in the training data. \n",
    "            - Doesnt consider the semantic relationship between the words ( books and chapter is related, or shoes and shirt can be related)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1adc0880-4329-41d9-847b-c60a1e6c9b3b",
   "metadata": {},
   "source": [
    "# TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6badc7-443e-4598-9a4e-90549dd9c88f",
   "metadata": {},
   "source": [
    "    - Tf-IDF \n",
    "        - Term Frequency   (TF)                 - Number of time a word has appeared / Total number of words in the document\n",
    "        - Inverse Document Frequency  (IDF)     - log(Total number of documents / No. of documents the word has appeared)\n",
    "        - TF-IDF                                - Term Frequency(TF) * Inverse Document Frequency(IDF)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "d6b3d489-c543-460c-a092-71aff70424f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I like this book',\n",
       " 'I dont like football',\n",
       " 'I am reading this book',\n",
       " 'I am a football fan']"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "79b01180-a35d-4a2d-b0e9-cb21187359b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "bbca9d49-a9d0-4129-affa-2e6d713b0847",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "vectors = vectorizer.fit_transform(text_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "2152a8c5-f6e2-49b1-8a71-10b039b21409",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.57735027, 0.        , 0.        , 0.        ,\n",
       "        0.57735027, 0.        , 0.57735027],\n",
       "       [0.        , 0.        , 0.66767854, 0.        , 0.52640543,\n",
       "        0.52640543, 0.        , 0.        ],\n",
       "       [0.46580855, 0.46580855, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.59081908, 0.46580855],\n",
       "       [0.52640543, 0.        , 0.        , 0.66767854, 0.52640543,\n",
       "        0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "792f0771-4a9c-4cbe-9d44-fdc99923db82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['am', 'book', 'dont', 'fan', 'football', 'like', 'reading', 'this'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names_out() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "474a1692-1f7a-48a6-83c7-e3974ff01650",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>am</th>\n",
       "      <th>book</th>\n",
       "      <th>dont</th>\n",
       "      <th>fan</th>\n",
       "      <th>football</th>\n",
       "      <th>like</th>\n",
       "      <th>reading</th>\n",
       "      <th>this</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.577350</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.577350</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.577350</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.667679</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.526405</td>\n",
       "      <td>0.526405</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.465809</td>\n",
       "      <td>0.465809</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.590819</td>\n",
       "      <td>0.465809</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.526405</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.667679</td>\n",
       "      <td>0.526405</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         am      book      dont       fan  football      like   reading  \\\n",
       "0  0.000000  0.577350  0.000000  0.000000  0.000000  0.577350  0.000000   \n",
       "1  0.000000  0.000000  0.667679  0.000000  0.526405  0.526405  0.000000   \n",
       "2  0.465809  0.465809  0.000000  0.000000  0.000000  0.000000  0.590819   \n",
       "3  0.526405  0.000000  0.000000  0.667679  0.526405  0.000000  0.000000   \n",
       "\n",
       "       this  label  \n",
       "0  0.577350      1  \n",
       "1  0.000000      0  \n",
       "2  0.465809      1  \n",
       "3  0.000000      0  "
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_set = pd.DataFrame(data = vectors.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "feature_set[\"label\"] = text_df[\"label\"]\n",
    "feature_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "93ba25bb-476f-4187-b653-cafca666561e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "clf_svm = svm.SVC(kernel = \"linear\")\n",
    "\n",
    "X_train =  vectors.toarray()\n",
    "y_train = text_df[\"label\"]\n",
    "\n",
    "clf_svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "b9fe534b-4923-43cc-b002-a15a5a15a1e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_text = [\"I like this book\",\"People watch football\", \"i  read books\",\"football is good\",\"books\", 'I am reading this book']\n",
    "pred_vector = (vectorizer.transform(pred_text)).toarray()\n",
    "\n",
    "\n",
    "# print(pred_vector)\n",
    "\n",
    "clf_svm.predict(pred_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5e52f7-ef02-434b-b2f8-e03d7876534d",
   "metadata": {},
   "source": [
    "    - Disadvantages of Count Vectorisation:\n",
    "            - It only considers those words which are present in the training data. \n",
    "            - Doesnt consider the semantic relationship between the words ( books and chapter is related, or shoes and shirt can be related)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ad6107-a43f-4b91-9595-84b0563c1f78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5928726c-ea4f-4edf-82f1-495bab3d4155",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf06f15-d887-4fc8-95e5-cfdb53b30022",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfdabeb-e2d5-4041-bf2b-a1be503b6eeb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0704cd-0058-4ad4-9ffc-5fe0ff16a6eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "66b669f1-f5ed-479f-a57e-71f85da56f48",
   "metadata": {},
   "source": [
    "# Word2Vec\n",
    "    - Handle the relationships between the words\n",
    "    - Consider the words which are not in the training data\n",
    "    - Gives similarity between words\n",
    "    \n",
    "    \n",
    "    \n",
    "    - Understands the semantic relationship\n",
    "    \n",
    "    'KING - MAN + WOMAN = QUEEN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "f1f0b892-ed99-4358-9ae0-336802ea124e",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data = ['I like this book',\n",
    "             'I dont like football',\n",
    "             \"Books are great for learning\",\n",
    "             'Football is a good sport']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "753a1721-a67f-400a-af50-41234d3b3f7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.10108825,  0.1753288 , -0.46511328, -0.58186936, -0.24014316,\n",
       "        0.18683529,  0.1151624 ,  0.2941464 ,  0.65600866, -0.15250449,\n",
       "        0.13406175, -0.53378177,  0.7110953 , -0.19966024,  0.03958007,\n",
       "       -0.47140816, -0.03733912,  0.2771263 , -0.8190035 , -0.4270077 ,\n",
       "        0.7018841 , -0.60961455,  0.7150829 ,  0.45296928,  1.0245095 ,\n",
       "        0.40628394,  1.095893  , -0.83086866,  0.4250836 ,  0.10669468,\n",
       "       -0.2223094 ,  0.28379348, -0.39372268,  0.2548144 , -0.08345608,\n",
       "       -0.44437304, -0.44359565, -0.35237408, -0.2669944 ,  0.22077931,\n",
       "       -0.19576967,  0.65629363,  0.5119625 , -0.20124204,  0.06920663,\n",
       "       -0.3317858 ,  0.3664886 ,  0.49511528, -0.7734642 , -0.41126522,\n",
       "       -0.16300905, -0.09808165,  0.03496218,  0.8300558 , -0.56442803,\n",
       "       -0.0997112 , -0.37365708,  0.4113036 ,  0.254392  , -0.02073604,\n",
       "       -0.58385825, -0.09051654, -0.24396247,  0.0168677 , -0.81754273,\n",
       "       -1.1022238 , -0.5932955 , -0.04311176,  0.41030392, -0.7480996 ,\n",
       "        0.08114836, -0.45062646, -0.21044189, -0.9857931 ,  0.5134848 ,\n",
       "       -0.1948783 ,  0.30473825, -0.55808157, -0.306648  ,  1.6654215 ,\n",
       "        0.5871381 , -0.02492871,  0.11564341,  0.656447  , -0.06028926,\n",
       "       -0.28211114, -0.06083961,  0.20253533, -0.8417755 ,  0.12303031,\n",
       "        0.13636911,  0.01732746, -0.22489661,  0.62984914,  0.11147571,\n",
       "       -0.31816348], dtype=float32)"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"I love football\"\n",
    "\n",
    "nlp(text).vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "82719a9c-c515-499a-bf9f-b4ffe363751e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[I like this book,\n",
       " I dont like football,\n",
       " Books are great for learning,\n",
       " Football is a good sport]"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = [ nlp(x) for x in   text_data]\n",
    "\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "b277b57c-d92e-4c47-9392-b42f37159092",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_w2v = []\n",
    "for sent in docs:\n",
    "    X_train_w2v.append(sent.vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "c0c97748-d246-4cad-9903-0de082fc1215",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I like this book',\n",
       " 'I dont like football',\n",
       " 'Books are great for learning',\n",
       " 'Football is a good sport']"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "d06a4681-4c07-486f-baa9-a548f89e3c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = [\"BOOKS\",\"FOOTBALL\",\"BOOKS\",\"FOOTBALL\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "4f38832d-b957-4562-add0-dd92d7f3c91e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BOOKS', 'FOOTBALL', 'BOOKS', 'FOOTBALL']"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "6af23383-430a-47c0-a7ee-71211e99acd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_w2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "e656a038-3b6c-45ba-8857-9698dabe65e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train_w2v, y_train)\n",
    "# clf_svm_w2v = svm.SVC(kernel = \"linear\")\n",
    "# clf_svm_w2v.fit(X_train_w2v, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0310b93e-4590-486a-a681-f684c0b6bdb3",
   "metadata": {},
   "source": [
    "### prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "99544e61-6115-4843-b763-b51cbf5ad29d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I like this book</td>\n",
       "      <td>BOOKS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>People watch football</td>\n",
       "      <td>FOOTBALL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i  read books</td>\n",
       "      <td>BOOKS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>football is good</td>\n",
       "      <td>BOOKS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>books</td>\n",
       "      <td>BOOKS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I am reading this book</td>\n",
       "      <td>BOOKS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>i like this chapter</td>\n",
       "      <td>BOOKS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>i am reading lesson 3</td>\n",
       "      <td>BOOKS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The page is good</td>\n",
       "      <td>BOOKS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Book content is good</td>\n",
       "      <td>BOOKS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Books are good for knowledge</td>\n",
       "      <td>BOOKS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Sports is good for health</td>\n",
       "      <td>BOOKS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Input Prediction\n",
       "0               I like this book      BOOKS\n",
       "1          People watch football   FOOTBALL\n",
       "2                  i  read books      BOOKS\n",
       "3               football is good      BOOKS\n",
       "4                          books      BOOKS\n",
       "5         I am reading this book      BOOKS\n",
       "6            i like this chapter      BOOKS\n",
       "7          i am reading lesson 3      BOOKS\n",
       "8               The page is good      BOOKS\n",
       "9           Book content is good      BOOKS\n",
       "10  Books are good for knowledge      BOOKS\n",
       "11     Sports is good for health      BOOKS"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_text = [\"I like this book\",\n",
    "             \"People watch football\", \n",
    "             \"i  read books\",\n",
    "             \"football is good\",\n",
    "             \"books\", \n",
    "             'I am reading this book',\n",
    "            \"i like this chapter\",\n",
    "            \"i am reading lesson 3\",\n",
    "            \"The page is good\",\n",
    "            \"Book content is good\",\n",
    "            \"Books are good for knowledge\",\n",
    "            \"Sports is good for health\"]\n",
    "X_test_w2v = []\n",
    "\n",
    "for sent in [ nlp(x) for x in  pred_text]:\n",
    "    X_test_w2v.append(sent.vector)\n",
    "    \n",
    "    \n",
    "preds = rf.predict(X_test_w2v)\n",
    "result = pd.DataFrame({\"Input\":pred_text, \"Prediction\":preds})\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154b4356-f990-4ce8-93a6-18df431e1930",
   "metadata": {},
   "source": [
    "### Another classification example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "3af39e04-f88a-4247-9863-d06b9d946234",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train_x = [\"i love the book\", \"this is a great book\", \"the shirt is good to  wear\", \"the shoes are nice\"]\n",
    "train_y = [\"BOOKS\", \"BOOKS\", \"CLOTHING\", \"CLOTHING\"]\n",
    "\n",
    "\n",
    "\n",
    "# train_x = [\"love book\", \" great book\", \" shirt good wear\", \"shoes nice\"] ---> after removing the stop words\n",
    "\n",
    "train_x_vectors = []\n",
    "for sent in [ nlp(x) for x in  train_x]:\n",
    "    train_x_vectors.append(sent.vector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "6347ff79-35b9-4295-9ebd-39d2ddfd7281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(the, True)"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0][2], docs[0][1].is_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cfd969-eccc-4a05-aa92-ca5721a5ae65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622ff935-ccf1-40e8-a357-58bdbb98bded",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "d8f04603-aa1c-4d35-bf25-1b363e338203",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BOOKS', 'BOOKS', 'CLOTHING', 'CLOTHING']"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "ba83fd6c-9368-478c-9094-0c228c273485",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "clf_svm = svm.SVC(kernel = \"linear\")\n",
    "clf_svm.fit(train_x_vectors, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "7a56870f-de64-471d-80ca-fcfe806bd785",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>shoes fit well</td>\n",
       "      <td>CLOTHING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i love to read this</td>\n",
       "      <td>CLOTHING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>interesting book to read</td>\n",
       "      <td>CLOTHING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i like the story</td>\n",
       "      <td>BOOKS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pants are good fit</td>\n",
       "      <td>CLOTHING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I am writing a novel</td>\n",
       "      <td>BOOKS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>This hat is good</td>\n",
       "      <td>CLOTHING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>i am reading a chapter</td>\n",
       "      <td>BOOKS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>I am wearing trousers</td>\n",
       "      <td>CLOTHING</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Input Prediction\n",
       "0            shoes fit well   CLOTHING\n",
       "1       i love to read this   CLOTHING\n",
       "2  interesting book to read   CLOTHING\n",
       "3          i like the story      BOOKS\n",
       "4        pants are good fit   CLOTHING\n",
       "5      I am writing a novel      BOOKS\n",
       "6          This hat is good   CLOTHING\n",
       "7    i am reading a chapter      BOOKS\n",
       "8     I am wearing trousers   CLOTHING"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x = [\"shoes fit well\",\n",
    "          \"i love to read this\",\n",
    "          \"interesting book to read\", \n",
    "          \"i like the story\",\n",
    "          \"pants are good fit\",\n",
    "         \"I am writing a novel\",\n",
    "         \"This hat is good\",\n",
    "         \"i am reading a chapter\",\n",
    "         \"I am wearing trousers\"]\n",
    "\n",
    "\n",
    "test_x_vectors = []\n",
    "\n",
    "for sent in [ nlp(x) for x in  test_x]:\n",
    "    test_x_vectors.append(sent.vector)\n",
    "    \n",
    "pred = clf_svm.predict(test_x_vectors)\n",
    "\n",
    "result = pd.DataFrame({\"Input\":test_x, \"Prediction\":pred})\n",
    "result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "17511601-b235-4b32-8c75-f4481210e172",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i love the book',\n",
       " 'this is a great book',\n",
       " 'the shirt is good to  wear',\n",
       " 'the shoes are nice']"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13eb3c63-6ed5-41cb-822f-ddc5a5336419",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
